{
    "batch_size": 32512,
    "subspace_dim": 4,
    "num_experts": 16384,
    "atoms_per_subspace": 16,
    "k": 32,
    "l1_penalty": 1e-3,
    "ortho_penalty": 1e-1,
    "num_epochs": 4,
    "wandb_run_name": "16k_16",
    "lr_peak": 5e-4,
    "lr_init": 1e-11,
    "norm_clip": 0.75,
    "warmup_steps": 1000,
    "bias": false,
    "save_checkpoints": null,
    "restore_from": false,
    "restore_step": null,
    "fsdp_shard": false
}
