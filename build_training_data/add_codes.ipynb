{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe78bb-e387-4ff0-bb94-50aa353c2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8ee73-0a3f-4684-a211-b9c152273c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f79b73-4038-46b9-8b98-cfdba9c2a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_df = df[['WP\\ncode','Active\\nusers']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Create an 'id' field starting at 0\n",
    "new_df['id'] = range(len(new_df))\n",
    "\n",
    "# Ensure 'en' and 'simple' have the same id value\n",
    "en_index = new_df[new_df['WP\\ncode'] == 'en'].index\n",
    "simple_index = new_df[new_df['WP\\ncode'] == 'simple'].index\n",
    "\n",
    "if not en_index.empty and not simple_index.empty:\n",
    "    en_value = new_df.loc[en_index, 'id'].values[0]\n",
    "    new_df.loc[simple_index, 'id'] = en_value\n",
    "    \n",
    "    # Adjust the ids for rows after 'simple'\n",
    "    rows_to_adjust = new_df.index > simple_index[0]\n",
    "    new_df.loc[rows_to_adjust, 'id'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442906c-7a0f-40eb-8b43-1cbfb4d48e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.sort_values(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50e757-1236-4559-8433-4735d207d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[new_df['id'] < 128]['Active\\nusers'].str.replace(',', '').astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40188b05-1665-4adb-9da1-039dd2831b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import SmallInteger, String\n",
    "# Insert the new DataFrame into the database\n",
    "new_df.to_sql('wikipedia_lang_code', engine, if_exists='replace', index=False, \n",
    "              dtype={'id': SmallInteger, 'WP\\ncode': String})\n",
    "\n",
    "print(\"Table 'wikipedia_lang_code' has been created/updated in the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7783d9ad-9c03-498c-a21c-1d30cdfd37f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import concurrent.futures\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "# Connect to the database\n",
    "connection_string = \"\" # SQL connection string, e.g. 'postgresql://muchane@localhost/interp'\n",
    "db_name = \"\" # SQL database name, e.g. 'interp'\n",
    "username = \"\" # DB username, e.g. 'muchane'\n",
    "url = \"\" # DB url/IP address, e.g. 127.0.0.1\n",
    "\n",
    "engine = create_engine('')\n",
    "\n",
    "# Load the wikipedia_lang_code table into a DataFrame\n",
    "lang_codes_df = new_df\n",
    "\n",
    "# Create a dictionary for faster lookups\n",
    "lang_id_dict = dict(zip(lang_codes_df['WP\\ncode'], lang_codes_df['id']))\n",
    "\n",
    "# Function to process a chunk of rows\n",
    "def process_chunk(chunk):\n",
    "    conn = psycopg2.connect(f\"dbname={db_name} user={username} host={url}\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Prepare data for updating\n",
    "    data = [(lang_id_dict.get(lang, None), id) for lang, id in zip(chunk['lang'], chunk['id'])]\n",
    "    \n",
    "    # Update the chunk\n",
    "    execute_values(cur, \n",
    "                   \"UPDATE wikipedia_text SET lang_id = data.lang_id FROM (VALUES %s) AS data(lang_id, id) WHERE wikipedia_text.id = data.id\",\n",
    "                   data)\n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "# Add lang_id column if it doesn't exist\n",
    "with engine.connect() as connection:\n",
    "    connection.execute(text(\"ALTER TABLE wikipedia_text ADD COLUMN IF NOT EXISTS lang_id SMALLINT\"))\n",
    "\n",
    "# Process the wikipedia_text table in chunks\n",
    "chunksize = 10000  # Adjust this based on your system's capabilities\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=64) as executor:  # Adjust max_workers as needed\n",
    "    for chunk in pd.read_sql(\"SELECT id, lang FROM wikipedia_text\", engine, chunksize=chunksize):\n",
    "        executor.submit(process_chunk, chunk)\n",
    "\n",
    "print(\"Processing complete. The 'lang_id' column has been added and populated.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
